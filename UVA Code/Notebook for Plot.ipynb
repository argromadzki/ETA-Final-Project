{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is the same code as in the word2vec base python file, just in hopes that it will hang less than in iPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from gensim.models import word2vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# os.getcwd()\n",
    "os.chdir('../../Data/')\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "#%% # # Process\n",
    "tokens = pd.read_csv('redo_token_mod.csv')\n",
    "tokens = tokens[~tokens.term_str.isna()]\n",
    "#%% # ## Import tokens and convert to a corpus for Gensim\n",
    "\n",
    "documents = pd.read_csv('redo_doc.csv') # , index_col='doc_id'\n",
    "combo = pd.merge(tokens, documents, on='doc_id')\n",
    "del(documents)\n",
    "del(tokens)\n",
    "\n",
    "#%%\n",
    "OHCO = ['year','month','day','section','sentence_num']\n",
    "\n",
    "corpus = combo.groupby(OHCO).term_str.apply(lambda  x:  x.tolist())    .reset_index()['term_str'].tolist()\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "# for article in corpus: # removed by the second line in tokens processes\n",
    "#     for word in article:\n",
    "#         if word =='nan':\n",
    "#             del(word)\n",
    "\n",
    "corpus[:5]\n",
    "#%% # ## Generate word embeddings with Gensim's library\n",
    "\n",
    "#%%\n",
    "model = word2vec.Word2Vec(corpus, size=246, window=5, min_count=200, workers=4)\n",
    "del(corpus)\n",
    "\n",
    "#%% # ## Visualize with tSNE\n",
    "#%% # ### Generate coordinates to plot\n",
    "\n",
    "#%%\n",
    "coords = pd.DataFrame(index=range(len(model.wv.vocab)))\n",
    "coords['label'] = [w for w in model.wv.vocab]\n",
    "coords['vector'] = coords['label'].apply(lambda x: model.wv.get_vector(x))\n",
    "\n",
    "#%% # ### Use ScikitLearn's TSNE library\n",
    "\n",
    "#%%\n",
    "tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "tsne_values = tsne_model.fit_transform(coords['vector'].tolist())\n",
    "\n",
    "\n",
    "#%%\n",
    "coords['x'] = tsne_values[:,0]\n",
    "coords['y'] = tsne_values[:,1]\n",
    "\n",
    "\n",
    "#%%\n",
    "coords.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_full = coords\n",
    "coords_full.to_csv(\"tsne_coordinates.csv\")\n",
    "coords = coords.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(800, 800)) \n",
    "for i in range(len(coords)):\n",
    "    plt.scatter(coords.x[i],coords.y[i])\n",
    "    plt.annotate(coords['label'][i],\n",
    "                 xy=(coords.x[i], coords.y[i]),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "plt.savefig('wsj wordcloud.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
